{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594b262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from torchmetrics.functional import r2_score as r2_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys \n",
    "import os\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchmetrics import MeanSquaredError\n",
    "# from pytorch_lightning import LightningModule, Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd())) \n",
    "from source.autoencoder import VariationalAutoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8bee1",
   "metadata": {},
   "source": [
    "### Simulate time series with intervals \n",
    "Now time series array of train data consists of 3 parts: mean values of daily incidence, low valuee of daily incidence and high values of daily incidence for each day. Therefore, the size of time series array is three times bigger than tmax -- number of simulation days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b6f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/network_model_interval_dataset_72.csv', index_col=0)\n",
    "tmax = int((df.values.shape[1] - 5)/3) # number of simulation days\n",
    "# 5 - number of parameters of the network model\n",
    "df['ts'] = df[['incidence_' + str(day_index) for day_index in range(tmax)] + \\\n",
    "              ['low_incidence_' + str(day_index) for day_index in range(tmax)] + \\\n",
    "              ['high_incidence_' + str(day_index) for day_index in range(tmax)]].values.tolist()\n",
    "data = df[['beta', 'alpha', 'ts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15172ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Диапазон параметров beta:[0.1, 0.9], alpha:[0.2, 0.9000000000000002]\n"
     ]
    }
   ],
   "source": [
    "print(r'Диапазон параметров beta:[{}, {}], alpha:[{}, {}]'.format(df['beta'].min(), df['beta'].max(),\n",
    "                                                                             df['alpha'].min(),\n",
    "                                                                             df['alpha'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42095841",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(data.drop(columns=['ts']), \n",
    "                                                     data.ts.values, \n",
    "                                                     test_size=0.33, \n",
    "                                                     random_state=42)\n",
    "X_train, X_test = X_train.values, X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e1d10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.tolist(), dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.tolist(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dba8253",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513924fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ee1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input):\n",
    "    custom_data_tensor = torch.tensor(input, dtype=torch.float32)\n",
    "    custom_data_tensor = custom_data_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pred, _, _ = model(custom_data_tensor)\n",
    "    return pred.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82bb32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test, y_test):\n",
    "    r2_sum = []\n",
    "    for (x, y) in zip(X_test, y_test):\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            pred = predict(model, x)\n",
    "            r2_sum.append(r2_score(y, pred))\n",
    "    print(f\"R2 Score: {np.array(r2_sum).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652eba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_loss(epoch, n_epochs, criterion, steps, pred, mu, logvar, gt, use=True):\n",
    "    if use:\n",
    "        if epoch/n_epochs < steps:\n",
    "            loss = criterion(pred ,gt)\n",
    "        else:\n",
    "            mse_loss = criterion(pred, gt)\n",
    "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            loss = mse_loss + kl_loss\n",
    "    else:\n",
    "        loss = criterion(pred, gt)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aefeba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e692fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epochs, train_loader, criterion, optimizer, scheduler=None):\n",
    "    tb = SummaryWriter()\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred, mu, logvar = model(X_batch.to(device))\n",
    "\n",
    "            loss = warmup_loss(epoch, n_epochs, criterion, 0, pred, mu, logvar, y_batch.to(device), use=False)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler != None:\n",
    "                scheduler.step()\n",
    "\n",
    "        tb.add_scalar(\"Total loss\", loss.item(), epoch)\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48698310",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "latent_size = 256\n",
    "n_epochs = 50\n",
    "\n",
    "mse_cr = F.mse_loss\n",
    "r2_cr = r2_loss\n",
    "vae = VariationalAutoencoder(input_size=2, hidden_size=hidden_size, latent_size=latent_size, output_size=3*tmax).to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "378b5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=25, T_mult=1, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbefdac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:58<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "train(vae, n_epochs, train_loader, mse_cr, optimizer, lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "278fda01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.024308249354362488\n"
     ]
    }
   ],
   "source": [
    "test(vae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52078f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_with_intervals(params, gt, fontsize=14):\n",
    "    surrogate_sim = predict(vae, params).numpy()\n",
    "    r2 = r2_score(gt, surrogate_sim)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax.plot(gt, label='Network model', marker='o', color='OrangeRed')\n",
    "    ax.plot(surrogate_sim, lw=3, color='RoyalBlue', label='Surrogate model')\n",
    "\n",
    "    ax.set_xlabel('Days', fontsize=1.2*fontsize)\n",
    "    ax.set_ylabel('Incidence', fontsize=1.2*fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "    ax.legend(fontsize=1.2*fontsize)\n",
    "    ax.grid()\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
